---
title: "Text Analysis of The Picture of Dorian Gray"
author: "Rose Determan"
output: pdf_document
---

```{r setup, include=FALSE,message=FALSE,results='hide', include = FALSE}
knitr::opts_chunk$set(echo = FALSE,include=FALSE,message=FALSE,results='hide', include = FALSE, warning = FALSE)

#imports ----------------------------------------------------------------------#
pacman::p_load(gutenbergr, tidyverse, tidytext, textdata, magrittr, dplyr,sentimentr, tnum,ggpubr)
bk <- gutenberg_download(gutenberg_id = 26740, mirror ="http://aleph.gutenberg.org")
```
# Synopsis and Characters
"The saying 'be careful what you wish for' has arguably never been more apt in literature than it is in this classic novel. When the young Victorian heartthrob Dorian Gray is influenced by Lord Henry Wotton's warning that he only has 'a few years in which to live really, perfectly, and fully' due to the transiency of his youthful beauty, he wishes for his portrait to change with time instead. Little does he know that he will soon stumble down the rocky road of moral corruption, committing one bad deed after another, destroying relationships with the people he meets at the same time as any good reputation he used to possess."
*Source: https://www.theguardian.com/childrens-books-site/2014/feb/13/review-picture-of-dorian-gray-oscar-wilde*  

**Main Characters:**  
Dorian Gray: Young man highly aware that his youth and beauty are fleeting and is obsessed with his image. He dies at the conclusion of the novel.  
Lord Henry Wotton: Exercises influence over Dorian. A bit of a philosopher and revolutionary.  
Basil Hallward: Talented painter who creates a portrait of Dorian and is enamored with him. He is killed by Dorian.  
Sibyl Vane: Young actress. Dorian's love interest in the novel. She dies by suicide after Dorian breaks her heart.  
*Source: https://www.sparknotes.com/lit/doriangray/characters/*
  
  
# Bag of Words Analysis
## Methods 
1. Import text from Project Gutenberg
2. Label rows with chapter ID and row ID
3. **Tokenize** the dataframe. This step takes a dataframe of lines of text and separates it into individual words. 
4. Remove **stop words** which are common words such as "every", "with", or "doing" (selected from ```stop_words``` dataset). 
5. Do the analysis
```{r}
#format text -- add line number and chapter number
start <- 34 #actual text of the book begins at row 34 
text<- bk[start:dim(bk)[1],] %>% 
   mutate(linenumber = row_number(),
          chapter = cumsum(str_detect(text, 
                                      regex("^chapter [\\divxlc]",
                                            ignore_case = TRUE))))

#separate into "tokens"/ single units -- words and remove "stop words"
tidy_text <- text %>% 
             unnest_tokens(word, text) %>% 
             anti_join(stop_words, by = "word")



count <- tidy_text %>% 
  count(word, sort = TRUE) %>%
  filter(n > 75) %>% 
   mutate(word = reorder(word, n)) %>% 
   mutate(part_of_speech = c("Character", "Character", "Noun", 
                  "Character","Character","Character","Character", 
                  "Noun","Noun","Noun","Noun","Noun", "Verb", 
                  "Verb", "Noun", "Verb", "Character", "Character", "Preposition", 
                  "Noun", "Noun", "Verb"))
```


```{r, fig.cap="The most common words (n>75) used in The Picture of Dorian Gray color coded by part of speech.", fig.width=7.5, fig.height=7.5/1.682, include = TRUE}
ggplot(data = count, aes(n, word, fill = part_of_speech)) +
  geom_col() +
  labs(y = NULL)+ theme_minimal() 
```
Figure 1 shows the count of the most common non-stop words in the Picture of Dorian Gray.  As we might expect words related to characters are most common. Interestingly the word "round" is one of the most common words. In the novel, Wilde does not use round as an adjective, but rather as a preposition, for example, "I turned half-way round, and saw Dorian Gray for the first time." 

## Sentiment Flow with lexicons
First using the Bing lexicon, I calculated the overall sentiment of the text. The Bing lexicon assigns a positive or negative sentiment to words. For example "beautiful" is coded as positive, and "corrupt" is coded as negative. If there are more negative words, as is true in *The Picture of Dorian Gray*, the result is a negative integer. 
```{r, include = TRUE}
#return net sentiment Bing
#https://www.kaggle.com/rtatman/tutorial-sentiment-analysis-in-r
tidy_text %>%
  inner_join(get_sentiments("bing"), by = "word") %>% # pull out only sentiment words
  count(sentiment) %>% # count the # of positive & negative words
  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
  mutate(sentiment = positive - negative) %>%  # # of positive words - # of negative words

knitr::kable(col.names = c("Count Negative", "Count Positive", "Net Sentiment"), caption = "Sentiment analysis using Bing Lexicon. Net sentiment = count of positive words - count of negative words")
```

Next I used the Afinn Lexicon which codes words with integers from -5 to 5. The only +5 word in the text is "superb," and there are no -5 words identified. Level -4 rated words include "torture" and "hell", for example. The average word sentiment is -0.2, and there were more negative words identified than positive ones.  

```{r, include = TRUE}
#average sentiment affin
tidy_text %>%
  inner_join(get_sentiments("afinn"), by = "word") %>% 
  mutate(binary = ifelse(value>0, "POSITIVE", "NEGATIVE")) %>%  
  group_by(binary) %>% 
  summarise(count = n()) %>%
  spread(binary, count, fill = 0) %>%  # made data wide rather than narrow
  cbind(tidy_text %>%
  inner_join(get_sentiments("afinn"), by = "word") %>% 
  mutate(binary = ifelse(value>0, "POSITIVE", "NEGATIVE")) %>%  
  summarise(mean = round(mean(value),2))) %>% 

knitr::kable(col.names = c("Count Negative", "Count Positive", "Mean Sentiment"), caption = "Sentiment analysis using Affin Lexicon. Mean sentiment = Average of sentiment values")
```

For the 3rd example following the textbook, I used the NRC Lexicon to identify sentiments. The NRC Lexicon codes words with a sentiment word, for example, the word "beautiful" is coded as both "joy" and "positive," while "accident" is coded as "fear", "negative", "sadness", and "surprise." I was surprised to find that more words are coded as positive than negative using the NRC lexicon. 
```{r, include = TRUE}
# sentiment NRC
tidy_text %>% inner_join(get_sentiments("nrc"), by = "word") %>% 
  group_by(sentiment) %>% 
  summarise(count = n(),
            proportion = round(n()/26897,2) ) %>% arrange(desc(count)) %>% 

knitr::kable(col.names = c("Sentiment", "Count of Words", "Proportion"), caption = "Sentiment analysis using NRC Lexicon. It is interesting that more words are coded as positive using this lexicon. Note: The proportions do not add to 100, since the proportion is based on all words in the text rather than the number of words that are matched in the lexicon. ")
```


```{r}
#create dataframes with lexicon words
afinn <- tidy_text %>% 
  inner_join(get_sentiments("afinn"), by = "word") %>% 
  group_by(index = linenumber %/% 25) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  tidy_text %>% 
    inner_join(get_sentiments("bing"), by = "word") %>%
    mutate(method = "Bing et al."),
  tidy_text %>% 
    inner_join(get_sentiments("nrc"), by = "word") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative")) %>% 
     mutate(method = "NRC")) %>%
     count(method, index = linenumber %/% 25, sentiment)%>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

```

```{r, message=FALSE,, include = TRUE, fig.cap = "Comparison of sentiment ratings based on lexicon. Each bar represents the sum of word sentiments in groups of 25 lines. Note that around index 250 (or around line 6250) there is a distinct group of negiive sentiments identified in all four lexicons.",fig.width=6.5, fig.height=4}
#read in new lexicon and join with existing text data
adj <- read_tsv("lexicons/adjectives/1890.tsv",col_names = c("word", "mean", "sd"))
freq <- read_tsv("lexicons/frequent_words/1890.tsv",col_names = c("word", "mean", "sd"))

new_lex <- rbind(adj, freq)
rm(adj, freq)

new <- tidy_text %>% 
  inner_join(new_lex) %>% 
  group_by(index = linenumber %/% 25) %>% 
  summarise(sentiment = sum(mean)) %>% 
  mutate(method = "1890")

#join the rows of all words and plot
bind_rows(new, afinn, bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")+ labs(title = "Comparison of Lexicons (including new)")
```
 
## Extra Lexicon
I've selected a lexicon that has common words from each decade.Words have changed meaning over time and in a sentiment analysis these differences should be considered. Since *The Picture of Dorian Gray* was published in 1890, I've selected the lexicon for the decade 1890. The lexicon can be accessed from the following link: *https://nlp.stanford.edu/projects/socialsent/*.  

Based on Figure 2, the lexicon with words and sentiments from 1890 matches well with the other lexicons. There are slight variations, as we would expect, but the trends are largely the same. The shared pattern is more distinct in the second half of the text. The average sentiment based on the year specific lexicon is 0.02, which suggests a slightly positive sentiment. This lexicon identifies "admirable", "beauty", and "fine" as the strongest positive words, and "cruelty", "terrible", and "wicked" as the strongest negitive words. 
 
William L. Hamilton, Kevin Clark, Jure Leskovec, and Dan Jurafsky. Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora. ArXiv preprint (arxiv:1606.02820). 2016. https://nlp.stanford.edu/projects/socialsent/

# Sentence Level Analysis
## Methods  
1. Set up true number space  
2. Read book with true numbers  
3. Use a query to access database with sentences  
4. Complete sentence level analysis  
```{r, results='hide', include = FALSE}
#set up space
tnum.authorize("mssp1.bu.edu")
tnum.setSpace("testspace")

#read book into true numbers
#source("Book2TN-v6A-1.R")
#tnBooksFromLines(bk$text, "Wilde_2")

#use a tnum query to get sentences
q1 <- tnum.query(query = "wilde_2/section# has text", max =30942)
df1<- tnum.objectsToDf(q1) 

rm(q1)

df1 <- df1 %>% select(subject, string.value) %>% na.omit()
df1$para <- as.factor(str_extract(df1$subject,"paragraph:\\d{1,}")) 
df1$para <- as.numeric(str_extract(df1$para,"\\d{1,}"))

sentences <- df1 %>% select(subject, string.value, para) %>% na.omit() %>% get_sentences() %>% sentiment() %>% na.omit()

sentences$note <- ifelse(sentences$para>=990 & sentences$para<1152, 1, 0)
```


## Sentimentr 
Using a similar plotting method, we can see the trends in sentence sentiment over the course of the text. This plot is similar to the bag of words plot, but a bit more scattered. For example, in the bag of words analysis, around index 250, there is a distinct negative sentiment detected in all of the lexicons, but in this analysis there is not the same pattern detected.   
This section of negative text corresponds with an area of conflict in the text where Dorian murders Basil.  Here are two example sentences. 

1 "The mad passions of a hunted animal stirred within him, and he loathed the man who was seated at the table, more than in his whole life he had ever loathed anything" (Sentimentr sentence rating: -0.451, Paragraph rating: -0.132)
2. "Gradually the events of the preceding night crept with silent blood-stained feet into his brain, and reconstructed themselves there with terrible distinctness.  (Sentimentr rating: -0.073, Paragraph rating: -0.327)  

Both of these sentences are clearly negative and are coded as such. The paragraphs are also coded as having a negative sentiment.



```{r, fig.cap = "Sentence level sentment grouped by paragraph. The pattern is similar to others that use a bag of words analysis, but the pattern is not the same. The orange bars represent the two chapters where Dorian kills Basil. Here some negative sentiment is detected, but these are not the most negative paragraphs identified.", fig.width=7.5, fig.height=4, include = TRUE}
p_sent <- sentences %>%  group_by(index = para) %>% 
  summarise(sentiment = mean(sentiment),
            wc = sum(word_count), 
            note = as.factor(mean(note))) 
ggplot(data = p_sent, aes(index, sentiment, fill = note)) +
  geom_col()+ xlab("Paragraph number") + labs(title = "Sentence Level Sentiment", subtitle = "grouped by paragraph")+
  scale_fill_brewer(palette = "Dark2")
```





# Character Analysis
```{r}
# create separate data frames for each character
dorian <- sentences %>% filter(grepl('Dorian|Gray', string.value))
lhenry <- sentences %>% filter(grepl('Henry|Harry|Wotton', string.value))
basil <- sentences %>% filter(grepl('Basil|Hallward', string.value))
sibyl <- sentences %>% filter(grepl('Sibyl|Vane', string.value))


# create separate data frames for co-occuring characters in sentences
dorian_henry <-sentences %>% filter(grepl("Dorian|Gray",string.value))%>%  filter(grepl('Henry|Harry|Wotton',string.value))
dorian_basil <-sentences %>% filter(grepl("Dorian|Gray",string.value))%>%  filter(grepl('Basil|Hallward',string.value))
dorian_sibyl <-sentences %>% filter(grepl("Dorian|Gray",string.value))%>%  filter(grepl('Sibyl|Vane',string.value))

```

## Histograms of character sentiments
I selected four of the main characters, and using the sentence sentiment values created histograms for the sentiment of sentences that mention the character's name. This method is not without fault though, since I do not identify sentences such as, "As a rule, he is charming to me, and we sit in the studio and talk of a thousand things" where Basil is describing his friendship with Dorian, because Basil only refers to Dorian as "he" rather than by his name. 
```{r, fig.height= 4, fig.width=7, "Character sentiment histograms. The vertical line represents the average sentiment for sentences that contain character's name.", include = TRUE }
d <- ggplot(dorian)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#999999", color = "white") +
  geom_vline(xintercept = mean(dorian$sentiment), color = "#666666", size = 1)+
  xlim(c(-1, 1))+
  labs(title = "Dorian Sentiment Histogram")
lh <- ggplot(lhenry)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#9691E6", color = "white") +
  geom_vline(xintercept = mean(lhenry$sentiment), color = "#7570B3", size = 1)+
  xlim(c(-1, 1))+
  labs(title = "Lord Henry Sentiment Histogram")

b <- ggplot(basil)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#86D927", color = "white") +
  geom_vline(xintercept = mean(basil$sentiment), color = "#66A61E", size = 1)+
  xlim(c(-1, 1.))+
  labs(title = "Basil Sentiment Histogram")
s <- ggplot(sibyl)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#F28FC6", color = "white") +
  geom_vline(xintercept = mean(sibyl$sentiment), color = "#CC79A7", size = 1)+
  xlim(c(-1, 1))+
  labs(title = "Sibyl Sentiment Histogram")


ggarrange(d,lh,b,s, ncol = 1, align = "hv")
```

Next, I plotted the character sentiment over time. The light gray bars represent all of the text and the black bars represent the text where the character is called by name. Some patterns arise that inform the plot of the book. For example, Dorian is the main character since there are sentences that refer to him throughout the text. We can also see where Sibyl dies approximately half way through the text in her plot since there is a strong negative sentiment identified. 

```{r, fig.cap="Timeline of sentence sentiment colored by character occurance", fig.width=7, fig.height=4, include = TRUE}
d_time <- ggplot(dorian)+
  geom_bar(data = sentences, mapping = aes(x = element_id, y = sentiment), color = "snow3",  stat = "Identity")+
  geom_bar(mapping = aes(x = element_id, y = sentiment), fill = "#999999", color = "black", stat = "Identity") +
  geom_hline(yintercept = 0, color = "gray")+
  labs(title = "Dorian Sentiment") + theme_minimal()

lh_time <- ggplot(lhenry)+
  geom_bar(data = sentences, mapping = aes(x = element_id, y = sentiment), color = "snow3",  stat = "Identity")+
  geom_bar(mapping = aes(x = element_id, y = sentiment), fill = "#999999", color = "black", stat = "Identity") +
  geom_hline(yintercept = 0, color = "gray")+
  labs(title = "Lord Henry Sentiment") + theme_minimal()

b_time <- ggplot(basil)+
  geom_bar(data = sentences, mapping = aes(x = element_id, y = sentiment), color = "snow3",  stat = "Identity")+
  geom_bar(mapping = aes(x = element_id, y = sentiment), fill = "#999999", color = "black", stat = "Identity") +
  geom_hline(yintercept = 0, color = "gray")+
  labs(title = "Basil Sentiment") + theme_minimal()

s_time <- ggplot(sibyl)+
  geom_bar(data = sentences, mapping = aes(x = element_id, y = sentiment), color = "snow3",  stat = "Identity")+
  geom_bar(mapping = aes(x = element_id, y = sentiment), fill = "#999999", color = "black", stat = "Identity") +
  geom_hline(yintercept = 0, color = "gray")+
  labs(title = "Sibyl Sentiment") + theme_minimal()

ggarrange(d_time,lh_time,b_time,s_time)
```



# Character co-occurance and sentiment histograms
A limitation of this analysis is that it does not differentiate between the character speaking or narrative. The following sentence is a simple narrative sentence. "Dorian Gray frowned and turned his head away." It is clear that Dorian is having some type of negative experience. In contrast, it is difficult to contextualize each sentence as a relationship between characters. For example, in this passage Basil is speaking about the inspiration that Dorian provides him. Wilde writes, "He is all my art to me now," said the painter, gravely... "What the invention of oil-painting was to the Venetians, the face of Antinoüs was to late Greek sculpture, and the face of Dorian Gray will some day be to me." Here, in several sentences, Basil conveys a positive sentiment towards Dorian, but in the analysis, only the name "Dorian Gray" is tagged. There is not a convenient way to indicate who is speaking about whom and how that relates to the sentiment. None the less, this analysis provides some insights into character relationships.   
I would be curious to extract information about how characters feel about eachother. For example, Basil is enamored with Dorian, but their friendship breaks down. For example, this passage narrates Dorian's feelings about Basil, "Basil had said things to him that were
unbearable, and that he had yet borne with patience. The murder had been
simply the madness of a moment."

```{r fig.cap = "Co-occurance of character's sentiment histogram", fig.width=7, fig.height=4, include = TRUE}
dlh <- ggplot(dorian_henry)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#9691E6", color = "white") +
  geom_vline(xintercept = mean(lhenry$sentiment), color = "#7570B3", size = 1)+
  xlim(c(-1.45, 1.45))+
  labs(title = "Lord Henry Sentiment Histogram")+
  labs(title = "Lord Henry and Dorian Sentiment")

db <- ggplot(dorian_basil)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#86D927", color = "white") +
  geom_vline(xintercept = mean(basil$sentiment), color = "#66A61E", size = 1)+
  xlim(c(-1.45, 1.45))+
  labs(title = "Basil and Dorian Sentiment")

ds <- ggplot(dorian_sibyl)+
  geom_histogram(mapping = aes(x = sentiment), binwidth=0.05, fill = "#F28FC6", color = "white") +
  geom_vline(xintercept = mean(sibyl$sentiment), color = "#CC79A7", size = 1)+
  xlim(c(-1.45, 1.45))+
  labs(title = "Sibyl and Dorian Sentiment")
ggarrange(dlh,db,ds, ncol = 1, align = "hv")+theme_light()
```
